{
  "metadata": {
    "name": "Manual_Importer",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\n#----- IMPORT PACKAGES -----#\nimport logging\nimport random\nimport string\nimport requests\nimport re\nimport pandas as pd\nimport numpy as np\nimport time\nimport traceback\nimport sys\nimport logging\nimport time\nimport socket\n\nfrom cassandra import ConsistencyLevel\nfrom cassandra.cluster import Cluster\nfrom cassandra.query import SimpleStatement\n\n\nip \u003d socket.gethostbyname(socket.gethostname())"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\nKEYSPACE \u003d \"test3\"\ncluster \u003d Cluster([ip])\nsession \u003d cluster.connect()\nsession.set_keyspace(KEYSPACE)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\n#----- DEFINE FUNCTION TO -----#\n#       - DOWNLOAD .CSV FILES\n#       - CREATE TABLES FOR EACH REQUEST\n#       - INSERT TABLES IN CASSANDRA\n\n#----- DOWNLOAD .CSV FILES-----#\ndef get_df(df_row):\n    col2keep \u003d {0: [0, 1, 2, 3, 12, 22, 31, 33, 34, 37, 45, 53, 60],\n                1: [0, 1, 5, 15],\n                2: [0, 1, 3, 4, 8, 10, 11, 12, 15]}\n    colnames \u003d {0: [\"GlobalEventID\",\n                   \"Day\",\n                   \"Month\",\n                   \"Year\",\n                   \"Actor1_Type1Code\",\n                   \"Actor2_Type1Code\",\n                   \"NumMentions\",\n                   \"NumArticles\",\n                   \"AverageTone\",\n                   \"Actor1_GeoCountryCode\",\n                   \"Actor2_GeoCountryCode\",\n                   \"Action_GeoCountryCode\",  #pas utilisé 04/02\n                   \"SourceURL\"],\n                1: [\"GlobalEventID\",\n                    \"EventTimeDate\",\n                    \"MentionID\",\n                    \"MentionDocTranslationalInfo\"],\n                2:[\"GKGRecordID\",\n                   \"Date\", #V2_1_\n                   \"SourceCommonName\", #V2_\n                   \"DocumentIdentifier\", #V2\n                   \"Themes\", #V2_Enhanced\n                   \"Locations\", #V2_Enhanced\n                   \"Persons\", #V1_ \n                   \"Organization\", #V2_Enhanced #pas utilisé 04/02\n                   \"Tone\"]} #V2_\n    names \u003d [\u0027events\u0027,\u0027mentions\u0027,\u0027gkg\u0027]\n    errors \u003d []\n    df_list \u003d {}\n    url_list \u003d [df_row[\u0027events\u0027],df_row[\u0027mentions\u0027],df_row[\u0027gkg\u0027]]\n    \n    for i, link in enumerate(url_list):\n        df_list[names[i]]\u003dpd.read_table(link,\n                                        header\u003dNone,\n                                        usecols\u003dcol2keep[i],\n                                        names\u003dcolnames[i],\n                                        encoding\u003d\u0027ISO-8859-1\u0027)\n    \n    # GKG preprocessing\n    gkg \u003d df_list[\"gkg\"].copy()\n    gkg \u003d gkg[gkg[\u0027Date\u0027].notna()]\n    gkg[\"Day\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:8]))\n    gkg[\"Month\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:6]))\n    gkg[\"Year\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:4]))\n    gkg[\"Themes\"] \u003d gkg[\"Themes\"].apply(lambda x: re.split(\";|,\", str(x))[:-1:2])\n    gkg[\"Persons\"] \u003d gkg[\"Persons\"].apply(lambda x: re.split(\";\", str(x)))\n    gkg[\"Organization\"] \u003d gkg[\"Organization\"].apply(lambda x: re.split(\";|,\", str(x))[:-1:2])\n    gkg[\"Tone\"] \u003d gkg[\"Tone\"].apply(lambda x: float(re.split(\",\", str(x))[0]))\n    gkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: str(x).replace(\"\u0027\", \" \"))\n    gkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: re.split(\";|#\", str(x))[1::9])\n    \n    gkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: \"{\u0027no location(s) mentionned\u0027}\" if x\u003d\u003d[] else \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\n    gkg[\"Persons\"] \u003d gkg[\"Persons\"].apply(lambda x: \"{\u0027no person(s) mentionned\u0027}\" if x\u003d\u003d[\u0027nan\u0027] else \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\n    \n    gkg[\"Themes\"] \u003d  gkg[\"Themes\"].apply(lambda x: \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\n    \n    \n    df_list[\"gkg\"] \u003d gkg \n    return df_list\n    \n    \n#----- CREATE TABLES FOR EACH REQUEST -----#\ndef getTable1(df_list):\n    table1 \u003d df_list[\u0027events\u0027][[\u0027GlobalEventID\u0027,\u0027Day\u0027,\u0027Action_GeoCountryCode\u0027]]\\\n        .merge(df_list[\u0027mentions\u0027][[\u0027GlobalEventID\u0027,\u0027MentionID\u0027,\u0027MentionDocTranslationalInfo\u0027]],\n                 on\u003d\"GlobalEventID\")\n    table1 \u003d table1[[\u0027GlobalEventID\u0027, \u0027Day\u0027, \u0027MentionID\u0027, \u0027Action_GeoCountryCode\u0027, \u0027MentionDocTranslationalInfo\u0027]]\n    table1 \u003dtable1.fillna(\u0027NA\u0027)\n    return table1\n\ndef getTable2(df_list):\n    table2 \u003d df_list[\u0027events\u0027][[\u0027GlobalEventID\u0027,\u0027Day\u0027,\u0027Month\u0027, \u0027Year\u0027,\u0027NumMentions\u0027,\u0027Action_GeoCountryCode\u0027]]\n    return table2\n\ndef getTable3(df_list):\n    table3 \u003d df_list[\u0027gkg\u0027][[\"Day\",\"Month\",\n                  \"SourceCommonName\",\n                  \"DocumentIdentifier\",\n                  \"Themes\",\n                  \"Locations\",\n                  \"Persons\",\n                  \"Tone\"]]\n    table3[\u0027Tone\u0027] \u003d table3[\u0027Tone\u0027].apply(lambda x: round(x,6))             \n    return table3\n\ndef getTable4(df_list):\n    table4 \u003d df_list[\u0027events\u0027][[\"SourceURL\", \"Day\", \"Month\", \"AverageTone\", \"Actor1_GeoCountryCode\",\n                                \"Actor2_GeoCountryCode\"]]\\\n        .merge(df_list[\u0027gkg\u0027][[\"DocumentIdentifier\", \"Themes\"]],\n                 left_on\u003d\"SourceURL\",\n                 right_on\u003d\"DocumentIdentifier\")\n    \n    # Enlever l\u0027une des colonnes ayant servis pour le merge.\n    table4 \u003d table4.drop([\"DocumentIdentifier\"], axis\u003d1)\n    \n    return table4\n\ndef makeTables(df_list):\n    tables \u003d {}\n    tables[\u0027nb_articles_events\u0027]\u003d getTable1(df_list)\n    tables[\u0027countries_events\u0027]\u003d getTable2(df_list)\n    tables[\u0027data_source\u0027]\u003d getTable3(df_list)\n    tables[\u0027relationship\u0027]\u003d getTable4(df_list)\n    return tables\n    \n\n#----- INSERT TABLES IN CASSANDRA -----#\ndef SQL_INSERT_STATEMENT_FROM_DATAFRAME(SOURCE, TARGET):\n    sql_texts \u003d []\n    for index, row in SOURCE.iterrows():\n        stat \u003d \u0027INSERT INTO \u0027+TARGET+\u0027 (\u0027+ str(\u0027, \u0027.join(SOURCE.columns))+ \u0027) VALUES \u0027+ str(tuple(row.values)).replace(\u0027\\\"{\\\u0027\u0027,\"{\u0027\")\n        stat \u003d stat.replace(\"\\\u0027}\\\"\",\"\\\u0027}\")\n       # stat \u003d stat.replace(\"\\\u0027null\\\u0027\",\" null \")\n        sql_texts.append( stat)\n    return sql_texts\n    \ndef urls_to_import(year, month, day, hours, minutes, df_file_list):\n    return df_file_list.filter(regex\u003d\u0027^\u0027+year+month+day+hours+minutes, axis\u003d0)\n    \n########### Helpers    \n    \ndef fetch_and_mark_data(session, amount : int ):\n    dates \u003d []\n    try:\n        rows \u003d session.execute(\u0027SELECT date FROM importstatus WHERE status \u003d \\\u0027pending\\\u0027 ALLOW FILTERING\u0027)\n        for idx, user_row in enumerate(rows):\n            dates.append(user_row.date)\n            statement \u003d f\u0027UPDATE importstatus SET status \u003d \\\u0027doing\\\u0027   WHERE date \u003d {user_row.date} IF EXISTS\u0027\n            session.execute(statement )\n            if idx  \u003eamount-2:\n                break\n            \n    except Exception as e:\n        print(e)\n        print(statement)\n    \n    return dates\n    \ndef make_df(to_import):\n    df \u003d pd.DataFrame(to_import,columns \u003d[\u0027date\u0027])\n    df[\u0027events\u0027] \u003d df[\u0027date\u0027].apply(lambda x:\u0027http://data.gdeltproject.org/gdeltv2/\u0027+str(x)+\u0027.export.CSV.zip\u0027 )\n    df[\u0027mentions\u0027] \u003d df[\u0027date\u0027].apply(lambda x:\u0027http://data.gdeltproject.org/gdeltv2/\u0027+str(x)+\u0027.mentions.CSV.zip\u0027 )\n    df[\u0027gkg\u0027] \u003d df[\u0027date\u0027].apply(lambda x:\u0027http://data.gdeltproject.org/gdeltv2/\u0027+str(x)+\u0027.gkg.csv.zip\u0027 )\n    \n    df \u003d df.set_index(\u0027date\u0027)\n\n    return df\n        "
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\nimport warnings\nwarnings.filterwarnings(\u0027ignore\u0027)\n\ndf_urls_to_import \u003d make_df(fetch_and_mark_data(session, 30))\nprint(len(df_urls_to_import))\ndoonnne \u003d0\nerrors \u003d {}\ntry:\n    for index, urls in df_urls_to_import.iterrows():\n        doonnne +\u003d1\n        try:\n            start_time \u003d time.perf_counter()\n            df_list_events_mentions_gkg \u003d get_df(urls)\n            tables_for_requests \u003d makeTables(df_list_events_mentions_gkg)\n            status \u003d {}\n            all_good \u003d True\n            for table in tables_for_requests:\n                done \u003d 0\n                SQL_test \u003d SQL_INSERT_STATEMENT_FROM_DATAFRAME(tables_for_requests[table].fillna(\u0027null\u0027), table)\n        \n                for statement in SQL_test:\n                    try:\n                        session.execute(statement)\n                        done+\u003d1\n                    except Exception as e:\n                        errors[str(index) + \u0027-\u0027 + str(done) + \"-\" +  table] \u003d {\"error\" : e}\n                        continue\n                    \n                statement \u003d f\u0027UPDATE importstatus SET {table} \u003d \\\u0027{done}/{len(SQL_test)}\\\u0027  WHERE date \u003d {index} IF EXISTS\u0027\n                if done !\u003d len(SQL_test) :\n                    all_good \u003d False\n                session.execute(statement)\n                \n                \n            \n            statement \u003d f\u0027UPDATE importstatus SET status \u003d \\\u0027done\\\u0027  WHERE date \u003d {index} IF EXISTS\u0027\n            if not all_good:\n                statement \u003d f\u0027UPDATE importstatus SET status \u003d \\\u0027partial_done\\\u0027  WHERE date \u003d {index} IF EXISTS\u0027\n            session.execute(statement)\n            \n            print(f\"{index} done in {time.perf_counter() - start_time}\" )\n        except Exception as e:\n            statement \u003d f\u0027UPDATE importstatus SET status \u003d \\\u0027failed\\\u0027  WHERE date \u003d {index} IF EXISTS\u0027\n            session.execute(statement)\n            print(f\"{index} failed in  {time.perf_counter() - start_time}\" )\n            print(e)\n            print(traceback.format_exc())\n            \nexcept Exception as e:\n    print(e)\n    print(traceback.format_exc())\n    print(f\u0027untrusted statement {statement}\u0027)\n    print(\u0027sleeping\u0027)\n    time.sleep(60*5)\n    try:\n        KEYSPACE \u003d \"gdelt_prod\"\n        cluster \u003d Cluster([ip])\n        session \u003d cluster.connect()\n        session.set_keyspace(KEYSPACE)\n    except Exception as e:\n        print(e)\n        print(traceback.format_exc())\n        "
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\nimport warnings\nwarnings.filterwarnings(\u0027ignore\u0027)\n\ndf_urls_to_import \u003d make_df([\u002720210325180000\u0027])"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\ndf_urls_to_import.values"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\ndf_urls_to_import\ndf_list_events_mentions_gkg \u003d get_df(df_urls_to_import.iloc[0])\n#tables_for_requests \u003d makeTables(df_list_events_mentions_gkg)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\ndf_row \u003d df_urls_to_import.iloc[0]\ncol2keep \u003d {0: [0, 1, 2, 3, 12, 22, 31, 33, 34, 37, 45, 53, 60],\n            1: [0, 1, 5, 15],\n            2: [0, 1, 3, 4, 8, 10, 11, 12, 15]}\ncolnames \u003d {0: [\"GlobalEventID\",\n               \"Day\",\n               \"Month\",\n               \"Year\",\n               \"Actor1_Type1Code\",\n               \"Actor2_Type1Code\",\n               \"NumMentions\",\n               \"NumArticles\",\n               \"AverageTone\",\n               \"Actor1_GeoCountryCode\",\n               \"Actor2_GeoCountryCode\",\n               \"Action_GeoCountryCode\",  #pas utilisé 04/02\n               \"SourceURL\"],\n            1: [\"GlobalEventID\",\n                \"EventTimeDate\",\n                \"MentionID\",\n                \"MentionDocTranslationalInfo\"],\n            2:[\"GKGRecordID\",\n               \"Date\", #V2_1_\n               \"SourceCommonName\", #V2_\n               \"DocumentIdentifier\", #V2\n               \"Themes\", #V2_Enhanced\n               \"Locations\", #V2_Enhanced\n               \"Persons\", #V1_ \n               \"Organization\", #V2_Enhanced #pas utilisé 04/02\n               \"Tone\"]} #V2_\nnames \u003d [\u0027events\u0027,\u0027mentions\u0027,\u0027gkg\u0027]\nerrors \u003d []\ndf_list \u003d {}\nurl_list \u003d [df_row[\u0027events\u0027],df_row[\u0027mentions\u0027],df_row[\u0027gkg\u0027]]\n\nfor i, link in enumerate(url_list):\n    df_list[names[i]]\u003dpd.read_table(link,\n                                    header\u003dNone,\n                                    usecols\u003dcol2keep[i],\n                                    names\u003dcolnames[i],\n                                    encoding\u003d\u0027ISO-8859-1\u0027)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\ngkg \u003d df_list[\"gkg\"].copy()\ngkg \u003d gkg[gkg[\u0027Date\u0027].notna()]\ngkg.info()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\ngkg \u003d df_list[\"gkg\"].copy()\ngkg[gkg[\u0027Date\u0027].isna()]\ngkg.info()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\n# GKG preprocessing\ngkg \u003d df_list[\"gkg\"].copy()\ngkg[\"Day\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:8]))\ngkg[\"Month\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:6]))\ngkg[\"Year\"] \u003d gkg[\"Date\"].apply(lambda x: int(str(x)[:4]))\ngkg[\"Themes\"] \u003d gkg[\"Themes\"].apply(lambda x: re.split(\";|,\", str(x))[:-1:2])\ngkg[\"Persons\"] \u003d gkg[\"Persons\"].apply(lambda x: re.split(\";\", str(x)))\ngkg[\"Organization\"] \u003d gkg[\"Organization\"].apply(lambda x: re.split(\";|,\", str(x))[:-1:2])\ngkg[\"Tone\"] \u003d gkg[\"Tone\"].apply(lambda x: float(re.split(\",\", str(x))[0]))\ngkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: str(x).replace(\"\u0027\", \" \"))\ngkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: re.split(\";|#\", str(x))[1::9])\n\ngkg[\"Locations\"] \u003d gkg[\"Locations\"].apply(lambda x: \"{\u0027no location(s) mentionned\u0027}\" if x\u003d\u003d[] else \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\ngkg[\"Persons\"] \u003d gkg[\"Persons\"].apply(lambda x: \"{\u0027no person(s) mentionned\u0027}\" if x\u003d\u003d[\u0027nan\u0027] else \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\n\ngkg[\"Themes\"] \u003d  gkg[\"Themes\"].apply(lambda x: \"{\u0027\"+\"\u0027, \u0027\".join(x)+\"\u0027}\")\n\n\ndf_list[\"gkg\"] \u003d gkg "
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python.ipython\n"
    }
  ]
}